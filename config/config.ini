[General]
llm_service = ollama
llm_api_url = http://localhost:11434/api/chat
model_name = llama3
verbosity = 1
