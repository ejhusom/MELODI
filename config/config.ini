[General]
llm_service = ollama
llm_api_url = http://localhost:11434/api/chat
model_name = llama3.2:1b
monitoring_service = energymeter
verbosity = 1
