[General]
llm_service = ollama
llm_api_url = http://localhost:11434/api/chat
model_name = deepseek-r1:1.5b-qwen-distill-fp16
verbosity = 1
