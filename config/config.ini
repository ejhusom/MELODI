[General]
llm_service = ollama
llm_api_url = http://localhost:11434/api/chat
model_name = qwen2
monitoring_service = melodi
verbosity = 1
